{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vSKgHSyLWGZ",
    "outputId": "e1ea9257-acd4-415e-b7f2-b45a5cd14308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt_dlp\n",
      "  Downloading yt_dlp-2024.10.22-py3-none-any.whl.metadata (171 kB)\n",
      "Collecting brotli (from yt_dlp)\n",
      "  Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in e:\\desktop\\hacktober\\env\\lib\\site-packages (from yt_dlp) (2024.8.30)\n",
      "Collecting mutagen (from yt_dlp)\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt_dlp)\n",
      "  Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.32.2 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from yt_dlp) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from yt_dlp) (2.2.3)\n",
      "Collecting websockets>=13.0 (from yt_dlp)\n",
      "  Downloading websockets-13.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests<3,>=2.32.2->yt_dlp) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests<3,>=2.32.2->yt_dlp) (3.10)\n",
      "Downloading yt_dlp-2024.10.22-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.6/3.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.9/3.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading websockets-13.1-cp312-cp312-win_amd64.whl (159 kB)\n",
      "Downloading Brotli-1.1.0-cp312-cp312-win_amd64.whl (357 kB)\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "Downloading pycryptodomex-3.21.0-cp36-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt_dlp\n",
      "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.21.0 websockets-13.1 yt_dlp-2024.10.22\n"
     ]
    }
   ],
   "source": [
    "!pip install yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kbQTjkti3sM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_z8RuaSAUgKi",
    "outputId": "3597d997-6989-4209-cd9a-cb77f753c11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in e:\\desktop\\hacktober\\env\\lib\\site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in e:\\desktop\\hacktober\\env\\lib\\site-packages (from openai==0.28) (3.10.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from aiohttp->openai==0.28) (1.16.0)\n",
      "Requirement already satisfied: colorama in e:\\desktop\\hacktober\\env\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\desktop\\hacktober\\env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->openai==0.28) (0.2.0)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.7\n",
      "    Uninstalling openai-0.27.7:\n",
      "      Successfully uninstalled openai-0.27.7\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P44a4K8oWw6a",
    "outputId": "944c02c7-45da-424b-987f-99fae168a08c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install yt_dlp git+https://github.com/openai/whisper.git -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bye1dZmpNYu"
   },
   "source": [
    "this is final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c2d8W9dVMe5",
    "outputId": "f012828b-6690-4ea9-9849-f4223add439d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in e:\\desktop\\hacktober\\env\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1ImDZ67VMcw",
    "outputId": "c56a56f9-c5af-4392-8c3f-7dd2b43d0948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio from URL: https://youtu.be/HyWYpM_S-2c?si=Y61aWwQsC6pZHI4I\n",
      "[youtube] Extracting URL: https://youtu.be/HyWYpM_S-2c?si=Y61aWwQsC6pZHI4I\n",
      "[youtube] HyWYpM_S-2c: Downloading webpage\n",
      "[youtube] HyWYpM_S-2c: Downloading ios player API JSON\n",
      "[youtube] HyWYpM_S-2c: Downloading mweb player API JSON\n",
      "[youtube] HyWYpM_S-2c: Downloading m3u8 information\n",
      "[info] HyWYpM_S-2c: Downloading 1 format(s): 251\n",
      "[download] Destination: video.webm\n",
      "[download] 100% of    2.79MiB in 00:00:01 at 2.16MiB/s   \n",
      "[ExtractAudio] Destination: video.mp3\n",
      "Deleting original file video.webm (pass -k to keep)\n",
      "Splitting audio into chunks from path: video.mp3\n",
      "Transcribing audio chunks...\n",
      "Transcribing chunk: chunk_0.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Desktop\\hacktober\\env\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "E:\\Desktop\\hacktober\\env\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing chunk: chunk_1.mp3\n",
      "Transcribing chunk: chunk_2.mp3\n",
      "Transcribed text:  React.js, a half-baked functional UI library created at Facebook that's used by millions of developers because it has a cool name and logo. It was invented by Mark Zuckerberg in 2013. And that was a big mistake. And it was my mistake. And I'm sorry. React is simple. It's just JavaScript, bro. And that's why it gives you dozens of weird ways to solve the same problems, like functional and class-based components, hooks, forward ref, higher-order components, mixins, render props, suspense, and so on. It's credited as the first declarative UI library, even though it took most of those ideas from AngularJS. Its killer feature, though, is the fact that you can write pure functional code. That is, until you want to do anything useful, in which case you'll need to write impure functions with state and effects. The beauty of this approach is that it makes simple things like reactive state much more complicated than they need to be. And that's what makes us feel like real developers. Use effect is especially fun and was originally going to be called useFootGun because it's a great way to introduce infinite loops, performance issues, and bugs that you'll never be able to figure out. Not to worry, though. React is always evolving with revolutionary new features to monkey patch all the weirdness, no-  nobody saw coming on the previous release. Now, even though it has an extremely high learning curve, React is a library and not a framework. And that means to build something cool, you'll need to find and install hundreds of different packages, most of which were built by teenagers who stopped maintaining them years ago when they went off to college to learn a real language like C. To get started, create a new React app, then open up Google to enter the gates of tutorial hell. Notice how we start in strict mode. That's used to hide baggage from previous versions of the framework. I mean, library. Now in the code, we pretend we're doing functional programming by writing our components as functions. But we also use the same shit classes everywhere. Instead, we use these hooks everywhere that do the same shit classes do in a more magical, hipster way. Templating is handled in JSX. It's a non-standard way to write HTML, which allows you to represent the UI entirely in non-portable callback hell. Now, we can all agree to hate CSS, but React will make you hate it even more when you try to style something on your own. Luckily, there are hundreds of CSS and JS libraries working on this problem as we speak. The extra complexity is worth it though, because React is blazingly fast. Assuming you  implemented all the weird tricks flawlessly. Life is about suffering. It's not supposed to be fun like Svelte, or fast like Solit, or liable like Angular, or all of the above like View. The only thing that matters is React is the most popular, and that makes it undeniably the best. Just like Microsoft makes the best operating system, and McDonald's makes the best food. This has been me destroying my reputation with the React community in 100 seconds. React has been the most influential library and friend and web development for the last decade. Nothing's perfect, but it got to where it is today because it does a lot of things right. And for that, it deserves our respect. Thanks for watching, and I will see you in the next one.\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Function to download audio from YouTube video\n",
    "def download_audio_from_youtube(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': 'video.%(ext)s',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "    return 'video.mp3'\n",
    "\n",
    "# Function to split audio into chunks\n",
    "def split_audio(file_path, chunk_length_ms=60000):\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
    "    chunk_files = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_file = f\"chunk_{i}.mp3\"\n",
    "        chunk.export(chunk_file, format=\"mp3\")\n",
    "        chunk_files.append(chunk_file)\n",
    "    return chunk_files\n",
    "\n",
    "# Function to convert audio to text using Whisper model\n",
    "def transcribe_audio(file_path):\n",
    "    model = whisper.load_model(\"small\")\n",
    "\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# Example usage\n",
    "video_url = \"https://youtu.be/HyWYpM_S-2c?si=Y61aWwQsC6pZHI4I\"\n",
    "\n",
    "# Step 1: Download audio from YouTube\n",
    "print(f\"Downloading audio from URL: {video_url}\")\n",
    "audio_path = download_audio_from_youtube(video_url)\n",
    "\n",
    "# Step 2: Split the audio into chunks\n",
    "print(f\"Splitting audio into chunks from path: {audio_path}\")\n",
    "chunk_files = split_audio(audio_path)\n",
    "\n",
    "# Step 3: Transcribe each chunk and combine results\n",
    "print(\"Transcribing audio chunks...\")\n",
    "transcriptions = []\n",
    "for chunk_file in chunk_files:\n",
    "    print(f\"Transcribing chunk: {chunk_file}\")\n",
    "    transcriptions.append(transcribe_audio(chunk_file))\n",
    "    os.remove(chunk_file)  # Clean up chunk file after transcription\n",
    "    time.sleep(1)  # Introduce a delay to avoid rate limiting\n",
    "\n",
    "transcribed_text = \" \".join(transcriptions)\n",
    "print(f\"Transcribed text: {transcribed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoTle8DzVMaY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxQcgFqlVMYJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hDwGYwFVMV3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
